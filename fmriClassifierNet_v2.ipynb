{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50, VGG19\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "#from keras.preprocessing import image\n",
    "#from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from matplotlib.pyplot import imread, imshow\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "import nibabel as nib\n",
    "import re\n",
    "from collections import Counter\n",
    "#import imageio\n",
    "from nst_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "#%aimport \n",
    "\n",
    "SEED=1\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#tf.set_random_seed(SEED)\n",
    "tf.random.set_seed\n",
    "\n",
    "K.clear_session()\n",
    "#K.set_image_data_format('channels_last')\n",
    "#K.set_learning_phase(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "For phase1, training examples are images shown to 4 participants across multiple sessions.\n",
    "\n",
    "Images labeled for 3 classes: scenes, coco, imgnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cs: CSI1 sess: 1 run: 1\n",
      "cs: CSI1 sess: 1 run: 2\n",
      "cs: CSI1 sess: 1 run: 3\n",
      "cs: CSI1 sess: 1 run: 4\n",
      "cs: CSI1 sess: 1 run: 5\n",
      "cs: CSI1 sess: 1 run: 6\n",
      "cs: CSI1 sess: 1 run: 7\n",
      "cs: CSI1 sess: 1 run: 8\n",
      "cs: CSI1 sess: 1 run: 9\n",
      "cs: CSI1 sess: 1 run: 10\n",
      "cs: CSI1 sess: 2 run: 1\n",
      "cs: CSI1 sess: 2 run: 2\n",
      "cs: CSI1 sess: 2 run: 3\n",
      "cs: CSI1 sess: 2 run: 4\n",
      "cs: CSI1 sess: 2 run: 5\n",
      "cs: CSI1 sess: 2 run: 6\n",
      "cs: CSI1 sess: 2 run: 7\n",
      "cs: CSI1 sess: 2 run: 8\n",
      "cs: CSI1 sess: 2 run: 9\n",
      "cs: CSI1 sess: 2 run: 10\n",
      "cs: CSI1 sess: 3 run: 1\n",
      "cs: CSI1 sess: 3 run: 2\n",
      "cs: CSI1 sess: 3 run: 3\n",
      "cs: CSI1 sess: 3 run: 4\n",
      "cs: CSI1 sess: 3 run: 5\n",
      "cs: CSI1 sess: 3 run: 6\n",
      "cs: CSI1 sess: 3 run: 7\n",
      "cs: CSI1 sess: 3 run: 8\n",
      "cs: CSI1 sess: 3 run: 9\n",
      "cs: CSI1 sess: 3 run: 10\n",
      "cs: CSI1 sess: 4 run: 1\n",
      "cs: CSI1 sess: 4 run: 2\n",
      "cs: CSI1 sess: 4 run: 3\n",
      "cs: CSI1 sess: 4 run: 4\n",
      "cs: CSI1 sess: 4 run: 5\n",
      "cs: CSI1 sess: 4 run: 6\n",
      "cs: CSI1 sess: 4 run: 7\n",
      "cs: CSI1 sess: 4 run: 8\n",
      "cs: CSI1 sess: 4 run: 9\n",
      "cs: CSI1 sess: 5 run: 1\n",
      "cs: CSI1 sess: 5 run: 2\n",
      "cs: CSI1 sess: 5 run: 3\n",
      "cs: CSI1 sess: 5 run: 4\n",
      "cs: CSI1 sess: 5 run: 5\n",
      "cs: CSI1 sess: 5 run: 6\n",
      "cs: CSI1 sess: 5 run: 7\n",
      "cs: CSI1 sess: 5 run: 8\n",
      "cs: CSI1 sess: 5 run: 9\n",
      "cs: CSI1 sess: 5 run: 10\n",
      "cs: CSI1 sess: 6 run: 1\n",
      "cs: CSI1 sess: 6 run: 2\n",
      "cs: CSI1 sess: 6 run: 3\n",
      "cs: CSI1 sess: 6 run: 4\n",
      "cs: CSI1 sess: 6 run: 5\n",
      "cs: CSI1 sess: 6 run: 6\n",
      "cs: CSI1 sess: 6 run: 7\n",
      "cs: CSI1 sess: 6 run: 8\n",
      "cs: CSI1 sess: 6 run: 9\n",
      "cs: CSI1 sess: 7 run: 1\n",
      "cs: CSI1 sess: 7 run: 2\n",
      "cs: CSI1 sess: 7 run: 3\n",
      "cs: CSI1 sess: 7 run: 4\n",
      "cs: CSI1 sess: 7 run: 5\n",
      "cs: CSI1 sess: 7 run: 6\n",
      "cs: CSI1 sess: 7 run: 7\n",
      "cs: CSI1 sess: 7 run: 8\n",
      "cs: CSI1 sess: 7 run: 9\n",
      "cs: CSI1 sess: 7 run: 10\n",
      "cs: CSI1 sess: 8 run: 1\n",
      "cs: CSI1 sess: 8 run: 2\n",
      "cs: CSI1 sess: 8 run: 3\n",
      "cs: CSI1 sess: 8 run: 4\n",
      "cs: CSI1 sess: 8 run: 5\n",
      "cs: CSI1 sess: 8 run: 6\n",
      "cs: CSI1 sess: 8 run: 7\n",
      "cs: CSI1 sess: 8 run: 8\n",
      "cs: CSI1 sess: 8 run: 9\n",
      "cs: CSI1 sess: 9 run: 1\n",
      "cs: CSI1 sess: 9 run: 2\n",
      "cs: CSI1 sess: 9 run: 3\n",
      "cs: CSI1 sess: 9 run: 4\n",
      "cs: CSI1 sess: 9 run: 5\n",
      "cs: CSI1 sess: 9 run: 6\n",
      "cs: CSI1 sess: 9 run: 7\n",
      "cs: CSI1 sess: 9 run: 8\n",
      "cs: CSI1 sess: 9 run: 9\n",
      "cs: CSI1 sess: 10 run: 1\n",
      "cs: CSI1 sess: 10 run: 2\n",
      "cs: CSI1 sess: 10 run: 3\n",
      "cs: CSI1 sess: 10 run: 4\n",
      "cs: CSI1 sess: 10 run: 5\n",
      "cs: CSI1 sess: 10 run: 6\n",
      "cs: CSI1 sess: 10 run: 7\n",
      "cs: CSI1 sess: 10 run: 8\n",
      "cs: CSI1 sess: 10 run: 9\n",
      "cs: CSI1 sess: 10 run: 10\n",
      "cs: CSI1 sess: 11 run: 1\n",
      "cs: CSI1 sess: 11 run: 2\n",
      "cs: CSI1 sess: 11 run: 3\n",
      "cs: CSI1 sess: 11 run: 4\n",
      "cs: CSI1 sess: 11 run: 5\n",
      "cs: CSI1 sess: 11 run: 6\n",
      "cs: CSI1 sess: 11 run: 7\n",
      "cs: CSI1 sess: 11 run: 8\n",
      "cs: CSI1 sess: 11 run: 9\n",
      "cs: CSI1 sess: 12 run: 1\n",
      "cs: CSI1 sess: 12 run: 2\n",
      "cs: CSI1 sess: 12 run: 3\n",
      "cs: CSI1 sess: 12 run: 4\n",
      "cs: CSI1 sess: 12 run: 5\n",
      "cs: CSI1 sess: 12 run: 6\n",
      "cs: CSI1 sess: 12 run: 7\n",
      "cs: CSI1 sess: 12 run: 8\n",
      "cs: CSI1 sess: 12 run: 9\n",
      "cs: CSI1 sess: 13 run: 1\n",
      "cs: CSI1 sess: 13 run: 2\n",
      "cs: CSI1 sess: 13 run: 3\n",
      "cs: CSI1 sess: 13 run: 4\n",
      "cs: CSI1 sess: 13 run: 5\n",
      "cs: CSI1 sess: 13 run: 6\n",
      "cs: CSI1 sess: 13 run: 7\n",
      "cs: CSI1 sess: 13 run: 8\n",
      "cs: CSI1 sess: 13 run: 9\n",
      "cs: CSI1 sess: 14 run: 1\n",
      "cs: CSI1 sess: 14 run: 2\n",
      "cs: CSI1 sess: 14 run: 3\n",
      "cs: CSI1 sess: 14 run: 4\n",
      "cs: CSI1 sess: 14 run: 5\n",
      "cs: CSI1 sess: 14 run: 6\n",
      "cs: CSI1 sess: 14 run: 7\n",
      "cs: CSI1 sess: 14 run: 8\n",
      "cs: CSI1 sess: 14 run: 9\n",
      "cs: CSI1 sess: 15 run: 1\n",
      "cs: CSI1 sess: 15 run: 2\n",
      "cs: CSI1 sess: 15 run: 3\n",
      "cs: CSI1 sess: 15 run: 4\n",
      "cs: CSI1 sess: 15 run: 5\n",
      "cs: CSI1 sess: 15 run: 6\n",
      "cs: CSI1 sess: 15 run: 7\n",
      "cs: CSI1 sess: 15 run: 8\n",
      "cs: CSI1 sess: 15 run: 9\n",
      "cs: CSI1 sess: 15 run: 10\n",
      "\n",
      "cs: CSI2 sess: 1 run: 1\n",
      "cs: CSI2 sess: 1 run: 2\n",
      "cs: CSI2 sess: 1 run: 3\n",
      "cs: CSI2 sess: 1 run: 4\n",
      "cs: CSI2 sess: 1 run: 5\n",
      "cs: CSI2 sess: 1 run: 6\n",
      "cs: CSI2 sess: 1 run: 7\n",
      "cs: CSI2 sess: 1 run: 8\n",
      "cs: CSI2 sess: 1 run: 9\n",
      "cs: CSI2 sess: 1 run: 10\n",
      "cs: CSI2 sess: 2 run: 1\n",
      "cs: CSI2 sess: 2 run: 2\n",
      "cs: CSI2 sess: 2 run: 3\n",
      "cs: CSI2 sess: 2 run: 4\n",
      "cs: CSI2 sess: 2 run: 5\n",
      "cs: CSI2 sess: 2 run: 6\n",
      "cs: CSI2 sess: 2 run: 7\n",
      "cs: CSI2 sess: 2 run: 8\n",
      "cs: CSI2 sess: 2 run: 9\n",
      "cs: CSI2 sess: 3 run: 1\n",
      "cs: CSI2 sess: 3 run: 2\n",
      "cs: CSI2 sess: 3 run: 3\n",
      "cs: CSI2 sess: 3 run: 4\n",
      "cs: CSI2 sess: 3 run: 5\n",
      "cs: CSI2 sess: 3 run: 6\n",
      "cs: CSI2 sess: 3 run: 7\n",
      "cs: CSI2 sess: 3 run: 8\n",
      "cs: CSI2 sess: 3 run: 9\n",
      "cs: CSI2 sess: 3 run: 10\n",
      "cs: CSI2 sess: 4 run: 1\n",
      "cs: CSI2 sess: 4 run: 2\n",
      "cs: CSI2 sess: 4 run: 3\n",
      "cs: CSI2 sess: 4 run: 4\n",
      "cs: CSI2 sess: 4 run: 5\n",
      "cs: CSI2 sess: 4 run: 6\n",
      "cs: CSI2 sess: 4 run: 7\n",
      "cs: CSI2 sess: 4 run: 8\n",
      "cs: CSI2 sess: 4 run: 9\n",
      "cs: CSI2 sess: 4 run: 10\n",
      "cs: CSI2 sess: 5 run: 1\n",
      "cs: CSI2 sess: 5 run: 2\n",
      "cs: CSI2 sess: 5 run: 3\n",
      "cs: CSI2 sess: 5 run: 4\n",
      "cs: CSI2 sess: 5 run: 5\n",
      "cs: CSI2 sess: 5 run: 6\n",
      "cs: CSI2 sess: 5 run: 7\n",
      "cs: CSI2 sess: 5 run: 8\n",
      "cs: CSI2 sess: 5 run: 9\n",
      "cs: CSI2 sess: 5 run: 10\n",
      "cs: CSI2 sess: 6 run: 1\n",
      "cs: CSI2 sess: 6 run: 2\n",
      "cs: CSI2 sess: 6 run: 3\n",
      "cs: CSI2 sess: 6 run: 4\n",
      "cs: CSI2 sess: 6 run: 5\n",
      "cs: CSI2 sess: 6 run: 6\n",
      "cs: CSI2 sess: 6 run: 7\n",
      "cs: CSI2 sess: 6 run: 8\n",
      "cs: CSI2 sess: 6 run: 9\n",
      "cs: CSI2 sess: 7 run: 1\n",
      "cs: CSI2 sess: 7 run: 2\n",
      "cs: CSI2 sess: 7 run: 3\n",
      "cs: CSI2 sess: 7 run: 4\n",
      "cs: CSI2 sess: 7 run: 5\n",
      "cs: CSI2 sess: 7 run: 6\n",
      "cs: CSI2 sess: 7 run: 7\n",
      "cs: CSI2 sess: 7 run: 8\n",
      "cs: CSI2 sess: 7 run: 9\n",
      "cs: CSI2 sess: 8 run: 1\n",
      "cs: CSI2 sess: 8 run: 2\n",
      "cs: CSI2 sess: 8 run: 3\n",
      "cs: CSI2 sess: 8 run: 4\n",
      "cs: CSI2 sess: 8 run: 5\n",
      "cs: CSI2 sess: 8 run: 6\n",
      "cs: CSI2 sess: 8 run: 7\n",
      "cs: CSI2 sess: 8 run: 8\n",
      "cs: CSI2 sess: 8 run: 9\n",
      "cs: CSI2 sess: 9 run: 1\n",
      "cs: CSI2 sess: 9 run: 2\n",
      "cs: CSI2 sess: 9 run: 3\n",
      "cs: CSI2 sess: 9 run: 4\n",
      "cs: CSI2 sess: 9 run: 5\n",
      "cs: CSI2 sess: 9 run: 6\n",
      "cs: CSI2 sess: 9 run: 7\n",
      "cs: CSI2 sess: 9 run: 8\n",
      "cs: CSI2 sess: 9 run: 9\n",
      "cs: CSI2 sess: 10 run: 1\n",
      "cs: CSI2 sess: 10 run: 2\n",
      "cs: CSI2 sess: 10 run: 3\n",
      "cs: CSI2 sess: 10 run: 4\n",
      "cs: CSI2 sess: 10 run: 5\n",
      "cs: CSI2 sess: 10 run: 6\n",
      "cs: CSI2 sess: 10 run: 7\n",
      "cs: CSI2 sess: 10 run: 8\n",
      "cs: CSI2 sess: 10 run: 9\n",
      "cs: CSI2 sess: 11 run: 1\n",
      "cs: CSI2 sess: 11 run: 2\n",
      "cs: CSI2 sess: 11 run: 3\n",
      "cs: CSI2 sess: 11 run: 4\n",
      "cs: CSI2 sess: 11 run: 5\n",
      "cs: CSI2 sess: 11 run: 6\n",
      "cs: CSI2 sess: 11 run: 7\n",
      "cs: CSI2 sess: 11 run: 8\n",
      "cs: CSI2 sess: 11 run: 9\n",
      "cs: CSI2 sess: 11 run: 10\n",
      "cs: CSI2 sess: 12 run: 1\n",
      "cs: CSI2 sess: 12 run: 2\n",
      "cs: CSI2 sess: 12 run: 3\n",
      "cs: CSI2 sess: 12 run: 4\n",
      "cs: CSI2 sess: 12 run: 5\n",
      "cs: CSI2 sess: 12 run: 6\n",
      "cs: CSI2 sess: 12 run: 7\n",
      "cs: CSI2 sess: 12 run: 8\n",
      "cs: CSI2 sess: 12 run: 9\n",
      "cs: CSI2 sess: 12 run: 10\n",
      "cs: CSI2 sess: 13 run: 1\n",
      "cs: CSI2 sess: 13 run: 2\n",
      "cs: CSI2 sess: 13 run: 3\n",
      "cs: CSI2 sess: 13 run: 4\n",
      "cs: CSI2 sess: 13 run: 5\n",
      "cs: CSI2 sess: 13 run: 6\n",
      "cs: CSI2 sess: 13 run: 7\n",
      "cs: CSI2 sess: 13 run: 8\n",
      "cs: CSI2 sess: 13 run: 9\n",
      "cs: CSI2 sess: 14 run: 1\n",
      "cs: CSI2 sess: 14 run: 2\n",
      "cs: CSI2 sess: 14 run: 3\n",
      "cs: CSI2 sess: 14 run: 4\n",
      "cs: CSI2 sess: 14 run: 5\n",
      "cs: CSI2 sess: 14 run: 6\n",
      "cs: CSI2 sess: 14 run: 7\n",
      "cs: CSI2 sess: 14 run: 8\n",
      "cs: CSI2 sess: 14 run: 9\n",
      "cs: CSI2 sess: 14 run: 10\n",
      "cs: CSI2 sess: 15 run: 1\n",
      "cs: CSI2 sess: 15 run: 2\n",
      "cs: CSI2 sess: 15 run: 3\n",
      "cs: CSI2 sess: 15 run: 4\n",
      "cs: CSI2 sess: 15 run: 5\n",
      "cs: CSI2 sess: 15 run: 6\n",
      "cs: CSI2 sess: 15 run: 7\n",
      "cs: CSI2 sess: 15 run: 8\n",
      "cs: CSI2 sess: 15 run: 9\n",
      "\n",
      "cs: CSI3 sess: 1 run: 1\n",
      "cs: CSI3 sess: 1 run: 2\n",
      "cs: CSI3 sess: 1 run: 3\n",
      "cs: CSI3 sess: 1 run: 4\n",
      "cs: CSI3 sess: 1 run: 5\n",
      "cs: CSI3 sess: 1 run: 6\n",
      "cs: CSI3 sess: 1 run: 7\n",
      "cs: CSI3 sess: 1 run: 8\n",
      "cs: CSI3 sess: 1 run: 9\n",
      "cs: CSI3 sess: 1 run: 10\n",
      "cs: CSI3 sess: 2 run: 1\n",
      "cs: CSI3 sess: 2 run: 2\n",
      "cs: CSI3 sess: 2 run: 3\n",
      "cs: CSI3 sess: 2 run: 4\n",
      "cs: CSI3 sess: 2 run: 5\n",
      "cs: CSI3 sess: 2 run: 6\n",
      "cs: CSI3 sess: 2 run: 7\n",
      "cs: CSI3 sess: 2 run: 8\n",
      "cs: CSI3 sess: 2 run: 9\n",
      "cs: CSI3 sess: 3 run: 1\n",
      "cs: CSI3 sess: 3 run: 2\n",
      "cs: CSI3 sess: 3 run: 3\n",
      "cs: CSI3 sess: 3 run: 4\n",
      "cs: CSI3 sess: 3 run: 5\n",
      "cs: CSI3 sess: 3 run: 6\n",
      "cs: CSI3 sess: 3 run: 7\n",
      "cs: CSI3 sess: 3 run: 8\n",
      "cs: CSI3 sess: 3 run: 9\n",
      "cs: CSI3 sess: 3 run: 10\n",
      "cs: CSI3 sess: 4 run: 1\n",
      "cs: CSI3 sess: 4 run: 2\n",
      "cs: CSI3 sess: 4 run: 3\n",
      "cs: CSI3 sess: 4 run: 4\n",
      "cs: CSI3 sess: 4 run: 5\n",
      "cs: CSI3 sess: 4 run: 6\n",
      "cs: CSI3 sess: 4 run: 7\n",
      "cs: CSI3 sess: 4 run: 8\n",
      "cs: CSI3 sess: 4 run: 9\n",
      "cs: CSI3 sess: 5 run: 1\n",
      "cs: CSI3 sess: 5 run: 2\n",
      "cs: CSI3 sess: 5 run: 3\n",
      "cs: CSI3 sess: 5 run: 4\n",
      "cs: CSI3 sess: 5 run: 5\n",
      "cs: CSI3 sess: 5 run: 6\n",
      "cs: CSI3 sess: 5 run: 7\n",
      "cs: CSI3 sess: 5 run: 8\n",
      "cs: CSI3 sess: 5 run: 9\n",
      "cs: CSI3 sess: 5 run: 10\n",
      "cs: CSI3 sess: 6 run: 1\n",
      "cs: CSI3 sess: 6 run: 2\n",
      "cs: CSI3 sess: 6 run: 3\n",
      "cs: CSI3 sess: 6 run: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs: CSI3 sess: 6 run: 5\n",
      "cs: CSI3 sess: 6 run: 6\n",
      "cs: CSI3 sess: 6 run: 7\n",
      "cs: CSI3 sess: 6 run: 8\n",
      "cs: CSI3 sess: 6 run: 9\n",
      "cs: CSI3 sess: 6 run: 10\n",
      "cs: CSI3 sess: 7 run: 1\n",
      "cs: CSI3 sess: 7 run: 2\n",
      "cs: CSI3 sess: 7 run: 3\n",
      "cs: CSI3 sess: 7 run: 4\n",
      "cs: CSI3 sess: 7 run: 5\n",
      "cs: CSI3 sess: 7 run: 6\n",
      "cs: CSI3 sess: 7 run: 7\n",
      "cs: CSI3 sess: 7 run: 8\n",
      "cs: CSI3 sess: 7 run: 9\n",
      "cs: CSI3 sess: 7 run: 10\n",
      "cs: CSI3 sess: 8 run: 1\n",
      "cs: CSI3 sess: 8 run: 2\n",
      "cs: CSI3 sess: 8 run: 3\n",
      "cs: CSI3 sess: 8 run: 4\n",
      "cs: CSI3 sess: 8 run: 5\n",
      "cs: CSI3 sess: 8 run: 6\n",
      "cs: CSI3 sess: 8 run: 7\n",
      "cs: CSI3 sess: 8 run: 8\n",
      "cs: CSI3 sess: 8 run: 9\n",
      "cs: CSI3 sess: 9 run: 1\n",
      "cs: CSI3 sess: 9 run: 2\n",
      "cs: CSI3 sess: 9 run: 3\n",
      "cs: CSI3 sess: 9 run: 4\n",
      "cs: CSI3 sess: 9 run: 5\n",
      "cs: CSI3 sess: 9 run: 6\n",
      "cs: CSI3 sess: 9 run: 7\n",
      "cs: CSI3 sess: 9 run: 8\n",
      "cs: CSI3 sess: 9 run: 9\n",
      "cs: CSI3 sess: 10 run: 1\n",
      "cs: CSI3 sess: 10 run: 2\n",
      "cs: CSI3 sess: 10 run: 3\n",
      "cs: CSI3 sess: 10 run: 4\n",
      "cs: CSI3 sess: 10 run: 5\n",
      "cs: CSI3 sess: 10 run: 6\n",
      "cs: CSI3 sess: 10 run: 7\n",
      "cs: CSI3 sess: 10 run: 8\n",
      "cs: CSI3 sess: 10 run: 9\n",
      "cs: CSI3 sess: 11 run: 1\n",
      "cs: CSI3 sess: 11 run: 2\n",
      "cs: CSI3 sess: 11 run: 3\n",
      "cs: CSI3 sess: 11 run: 4\n",
      "cs: CSI3 sess: 11 run: 5\n",
      "cs: CSI3 sess: 11 run: 6\n",
      "cs: CSI3 sess: 11 run: 7\n",
      "cs: CSI3 sess: 11 run: 8\n",
      "cs: CSI3 sess: 11 run: 9\n",
      "cs: CSI3 sess: 11 run: 10\n",
      "cs: CSI3 sess: 12 run: 1\n",
      "cs: CSI3 sess: 12 run: 2\n",
      "cs: CSI3 sess: 12 run: 3\n",
      "cs: CSI3 sess: 12 run: 4\n",
      "cs: CSI3 sess: 12 run: 5\n",
      "cs: CSI3 sess: 12 run: 6\n",
      "cs: CSI3 sess: 12 run: 7\n",
      "cs: CSI3 sess: 12 run: 8\n",
      "cs: CSI3 sess: 12 run: 9\n",
      "cs: CSI3 sess: 13 run: 1\n",
      "cs: CSI3 sess: 13 run: 2\n",
      "cs: CSI3 sess: 13 run: 3\n",
      "cs: CSI3 sess: 13 run: 4\n",
      "cs: CSI3 sess: 13 run: 5\n",
      "cs: CSI3 sess: 13 run: 6\n",
      "cs: CSI3 sess: 13 run: 7\n",
      "cs: CSI3 sess: 13 run: 8\n",
      "cs: CSI3 sess: 13 run: 9\n",
      "cs: CSI3 sess: 14 run: 1\n",
      "cs: CSI3 sess: 14 run: 2\n",
      "cs: CSI3 sess: 14 run: 3\n",
      "cs: CSI3 sess: 14 run: 4\n",
      "cs: CSI3 sess: 14 run: 5\n",
      "cs: CSI3 sess: 14 run: 6\n",
      "cs: CSI3 sess: 14 run: 7\n",
      "cs: CSI3 sess: 14 run: 8\n",
      "cs: CSI3 sess: 14 run: 9\n",
      "cs: CSI3 sess: 15 run: 1\n",
      "cs: CSI3 sess: 15 run: 2\n",
      "cs: CSI3 sess: 15 run: 3\n",
      "cs: CSI3 sess: 15 run: 4\n",
      "cs: CSI3 sess: 15 run: 5\n",
      "cs: CSI3 sess: 15 run: 6\n",
      "cs: CSI3 sess: 15 run: 7\n",
      "cs: CSI3 sess: 15 run: 8\n",
      "cs: CSI3 sess: 15 run: 9\n",
      "cs: CSI3 sess: 15 run: 10\n",
      "\n",
      "cs: CSI4 sess: 1 run: 1\n",
      "cs: CSI4 sess: 1 run: 2\n",
      "cs: CSI4 sess: 1 run: 3\n",
      "cs: CSI4 sess: 1 run: 4\n",
      "cs: CSI4 sess: 1 run: 5\n",
      "cs: CSI4 sess: 1 run: 6\n",
      "cs: CSI4 sess: 1 run: 7\n",
      "cs: CSI4 sess: 1 run: 8\n",
      "cs: CSI4 sess: 1 run: 9\n",
      "cs: CSI4 sess: 1 run: 10\n",
      "cs: CSI4 sess: 2 run: 1\n",
      "cs: CSI4 sess: 2 run: 2\n",
      "cs: CSI4 sess: 2 run: 3\n",
      "cs: CSI4 sess: 2 run: 4\n",
      "cs: CSI4 sess: 2 run: 5\n",
      "cs: CSI4 sess: 2 run: 6\n",
      "cs: CSI4 sess: 2 run: 7\n",
      "cs: CSI4 sess: 2 run: 8\n",
      "cs: CSI4 sess: 2 run: 9\n",
      "cs: CSI4 sess: 3 run: 1\n",
      "cs: CSI4 sess: 3 run: 2\n",
      "cs: CSI4 sess: 3 run: 3\n",
      "cs: CSI4 sess: 3 run: 4\n",
      "cs: CSI4 sess: 3 run: 5\n",
      "cs: CSI4 sess: 3 run: 6\n",
      "cs: CSI4 sess: 3 run: 7\n",
      "cs: CSI4 sess: 3 run: 8\n",
      "cs: CSI4 sess: 3 run: 9\n",
      "cs: CSI4 sess: 4 run: 1\n",
      "cs: CSI4 sess: 4 run: 2\n",
      "cs: CSI4 sess: 4 run: 3\n",
      "cs: CSI4 sess: 4 run: 4\n",
      "cs: CSI4 sess: 4 run: 5\n",
      "cs: CSI4 sess: 4 run: 6\n",
      "cs: CSI4 sess: 4 run: 7\n",
      "cs: CSI4 sess: 4 run: 8\n",
      "cs: CSI4 sess: 4 run: 9\n",
      "cs: CSI4 sess: 4 run: 10\n",
      "cs: CSI4 sess: 5 run: 1\n",
      "cs: CSI4 sess: 5 run: 2\n",
      "cs: CSI4 sess: 5 run: 3\n",
      "cs: CSI4 sess: 5 run: 4\n",
      "cs: CSI4 sess: 5 run: 5\n",
      "cs: CSI4 sess: 5 run: 6\n",
      "cs: CSI4 sess: 5 run: 7\n",
      "cs: CSI4 sess: 5 run: 8\n",
      "cs: CSI4 sess: 5 run: 9\n",
      "cs: CSI4 sess: 6 run: 1\n",
      "cs: CSI4 sess: 6 run: 2\n",
      "cs: CSI4 sess: 6 run: 3\n",
      "cs: CSI4 sess: 6 run: 4\n",
      "cs: CSI4 sess: 6 run: 5\n",
      "cs: CSI4 sess: 6 run: 6\n",
      "cs: CSI4 sess: 6 run: 7\n",
      "cs: CSI4 sess: 6 run: 8\n",
      "cs: CSI4 sess: 6 run: 9\n",
      "cs: CSI4 sess: 7 run: 1\n",
      "cs: CSI4 sess: 7 run: 2\n",
      "cs: CSI4 sess: 7 run: 3\n",
      "cs: CSI4 sess: 7 run: 4\n",
      "cs: CSI4 sess: 7 run: 5\n",
      "cs: CSI4 sess: 7 run: 6\n",
      "cs: CSI4 sess: 7 run: 7\n",
      "cs: CSI4 sess: 7 run: 8\n",
      "cs: CSI4 sess: 7 run: 9\n",
      "cs: CSI4 sess: 8 run: 1\n",
      "cs: CSI4 sess: 8 run: 2\n",
      "cs: CSI4 sess: 8 run: 3\n",
      "cs: CSI4 sess: 8 run: 4\n",
      "cs: CSI4 sess: 8 run: 5\n",
      "cs: CSI4 sess: 8 run: 6\n",
      "cs: CSI4 sess: 8 run: 7\n",
      "cs: CSI4 sess: 8 run: 8\n",
      "cs: CSI4 sess: 8 run: 9\n",
      "cs: CSI4 sess: 9 run: 1\n",
      "cs: CSI4 sess: 9 run: 2\n",
      "cs: CSI4 sess: 9 run: 3\n",
      "cs: CSI4 sess: 9 run: 4\n",
      "cs: CSI4 sess: 9 run: 5\n",
      "cs: CSI4 sess: 9 run: 6\n",
      "cs: CSI4 sess: 9 run: 7\n",
      "cs: CSI4 sess: 9 run: 8\n",
      "cs: CSI4 sess: 9 run: 9\n",
      "cs: CSI4 sess: 9 run: 10\n",
      "19380\n"
     ]
    }
   ],
   "source": [
    "# Get a global list of images file path with index matching trained data\n",
    "\n",
    "stimulusDirPath = os.path.join('images', 'BOLD5000_Stimuli', 'Scene_Stimuli', 'Presented_Stimuli')\n",
    "\n",
    "global_data = {\n",
    "        \"participant_list\": [\"CSI1\", \"CSI2\", \"CSI3\", \"CSI4\"],\n",
    "        \"start_sess\": 0,\n",
    "        \"last_sess\": 16,\n",
    "        \"start_run\": 0,\n",
    "        \"last_run\": 15\n",
    "}\n",
    "\n",
    "gList = {}\n",
    "global_index = 0\n",
    "imagePathList = []\n",
    "blankImage = 'Blank'\n",
    "\n",
    "for participant in global_data['participant_list']:\n",
    "        print()\n",
    "        # CS1 file are missing 1 after CSI\n",
    "        if participant == \"CSI1\":\n",
    "            CSI = \"CSI\"\n",
    "        else:\n",
    "            CSI = participant\n",
    "        \n",
    "        gList[participant] = {}\n",
    "        for sNum in range(global_data['start_sess'], global_data['last_sess']):\n",
    "            sSes = \"sess\" + str(sNum).zfill(2)\n",
    "            gList[participant][sSes] = {}\n",
    "            for rNum in range(global_data['start_run'], global_data['last_run']):\n",
    "                sRun = \"run\" + str(rNum).zfill(2)\n",
    "                dir_path = os.path.join(\"images\",\"BOLD5000_Stimuli\", \"Stimuli_Presentation_Lists\",participant, participant + \"_\" + sSes)\n",
    "                if not os.path.exists(dir_path):\n",
    "                    continue\n",
    "\n",
    "                stimulusListFilename = os.path.join(dir_path, \"_\".join([CSI, sSes, sRun]) + \".txt\")\n",
    "                if not os.path.exists(stimulusListFilename):\n",
    "                    continue\n",
    "                    \n",
    "                print(\"cs: %s sess: %s run: %s\" % (participant, sNum, rNum))\n",
    "                with open(stimulusListFilename) as f:\n",
    "                    imageList = f.read().splitlines()\n",
    "                    gList[participant][sSes][sRun] = imageList\n",
    "                    #global_index += len(fileList)\n",
    "                    for imageFileName in imageList:\n",
    "                        for (currDir, _, fileList) in os.walk(stimulusDirPath):\n",
    "                            currBaseDir = os.path.basename(currDir)\n",
    "                            for filename in fileList:\n",
    "                                if filename in imageFileName:\n",
    "                                    fullFilename = os.path.join(currDir, filename)\n",
    "                                    imagePathList.append(fullFilename)\n",
    "                                    #print(fullFilename)\n",
    "                                    break\n",
    "\n",
    "                #last index for no image\n",
    "                #global_index += 1\n",
    "                imagePathList.append(blankImage)\n",
    "\n",
    "                    \n",
    "#print(global_index)\n",
    "print(len(imagePathList))\n",
    "\n",
    "# Other way to get global index from events file. just ran this to verify above\n",
    "#from glob import glob\n",
    "#import pandas as pd\n",
    "#import os\n",
    "#\n",
    "#events_dir = '/home/ubuntu/cs230Project/dataset/ds001499-download'\n",
    "#iCount = 0\n",
    "#imageList = []\n",
    "#for subname in ['sub-CSI1', 'sub-CSI2', 'sub-CSI3', 'sub-CSI4']:\n",
    "#    for sNum in range(0, 20):\n",
    "#        ses = \"ses-%s\" % str(sNum).zfill(2)\n",
    "#        event_path = os.path.join(events_dir,subname,ses,'func','*run*' + '_events.tsv')\n",
    "#        event = glob(event_path)\n",
    "#        if not event:\n",
    "#            continue\n",
    "#\n",
    "#        event_file = glob(os.path.join(events_dir,subname,ses,'func','*' + 'run*' + '_events.tsv'))\n",
    "#        for ev in event_file:\n",
    "#            events = pd.read_csv(ev, sep = '\\t')\n",
    "#            for index, row in events.iterrows():\n",
    "#                iCount += 1\n",
    "#                imageList.append(row['ImgName'])\n",
    "#                #print(iCount)\n",
    "#\n",
    "#            # index for no image\n",
    "#            iCount += 1\n",
    "#            imageList.append('None')\n",
    "#\n",
    "#print(iCount)\n",
    "#print(len(imageList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50()\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model = Model(inputs = base_model.input, outputs = base_model.get_layer('avg_pool').output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19380\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "image_activations = []\n",
    "for imgFile in imagePathList:\n",
    "    if imgFile is blankImage:\n",
    "        image_activations.append(None)\n",
    "        continue\n",
    "\n",
    "    img = image.load_img(imgFile, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    image_activations.append(preprocess_input(x))\n",
    "\n",
    "print(len(image_activations))\n",
    "print(image_activations[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imageActivation = \"imageActivation\"\n",
    "activationFile = \"stActivations.npy\"\n",
    "!mkdir -p imageActivation\n",
    "imageActivationFile = os.path.join(imageActivation, activationFile)\n",
    "\n",
    "with open(imageActivationFile, 'wb') as f:\n",
    "    pickle.dump(image_activations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train encoder .. fmri to image activation vector\n",
    "ROI_list = [\n",
    "    'X_LHPPA.npy', #(19380, 5, 100)\n",
    "    'X_RHLOC.npy', #(19380, 5, 170)\n",
    "    'X_LHLOC.npy', #(19380, 5, 130)\n",
    "    'X_RHEarlyVis.npy', #(19380, 5, 220)\n",
    "    'X_RHRSC.npy', #(19380, 5, 100)\n",
    "    'X_RHOPA.npy', #(19380, 5, 80)\n",
    "    'X_RHPPA.npy', #(19380, 5, 140)\n",
    "    'X_LHEarlyVis.npy', #(19380, 5, 190)\n",
    "    'X_LHRSC.npy', #(19380, 5, 30)\n",
    "    'X_LHOPA.npy', #(19380, 5, 70)\n",
    "]\n",
    "\n",
    "#x_all (19380, 5, 1230)\n",
    "#y_all shape (19380, 17)\n",
    "\n",
    "#one way is to concatenate last dimenesion and just use 5 time series\n",
    "# so lstm input would be \n",
    "# other way is to train each roi seperately to encode to feature vector. and then inout feature vectoers to classify\n",
    "# or input roi as LSTM nodes to get one feature vector\n",
    "\n",
    "train_folder = '/home/ubuntu/cs230Project/dataset/traindata'\n",
    "array_list = []\n",
    "for roc_file in ROI_list:\n",
    "    xt_file_path = os.path.join(train_folder, roc_file)\n",
    "    xtrain_n = np.load(xt_file_path)\n",
    "    array_list.append(xtrain_n)\n",
    "    #print(xtrain_n.shape)\n",
    "\n",
    "#all_x = np.asarray(array_list)\n",
    "#print(all_x.shape)\n",
    "x_all = np.dstack(array_list)\n",
    "print(x_all.shape)\n",
    "\n",
    "yt_file_path = os.path.join(train_folder, 'Yreal_all.npy')\n",
    "y_all = np.load(yt_file_path)\n",
    "\n",
    "num_classes = y_all.shape[1]\n",
    "\n",
    "x_train = x_all[0:18380, :, :]\n",
    "y_train = y_all[0:18380, :]\n",
    "x_test = x_all[18380:, :, :]\n",
    "y_test = y_all[18380:, :]\n",
    "\n",
    "def classifer_lstm(input_shape, num_classes):\n",
    "    X_input = Input(input_shape)\n",
    "    X = LSTM(512, dropout=0.2)(X_input)\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(num_classes, activation = \"softmax\")(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='auto_encoder_lstm')\n",
    "    return model\n",
    "\n",
    "Tx = x_train.shape[1]\n",
    "Voxels = x_train.shape[2]\n",
    "classifier_lstm = classifer_lstm((Tx, Voxels), num_classes)\n",
    "\n",
    "EPOCHS=100\n",
    "#callbacks\n",
    "#callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "#             ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "\n",
    "#callbacks = [ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "classifier_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train_history = classifier_lstm.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=35, validation_data=(x_test, y_test))\n",
    "train_history = classifier_lstm.fit(x=x_train, y=y_train, epochs=EPOCHS, batch_size=35, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activations from pretrained model and saved to file\n",
    "activations = {x: pretrained_model.predict(X_images[x]) for x in sorted(X_images.keys())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stList = {}\n",
    "stimulusDirPath = os.path.join('images', 'BOLD5000_Stimuli', 'Scene_Stimuli', 'Presented_Stimuli')\n",
    "print(\"stimulusDirPath: %s\" % stimulusDirPath)\n",
    "\n",
    "   \n",
    "#data_split = {\n",
    "#    \"train\": {\n",
    "#        \"participant_list\": [\"CSI1\", \"CSI2\", \"CSI3\"],\n",
    "#        \"start_sess\": 1,\n",
    "#        \"last_sess\": 14,\n",
    "#        \"start_run\": 1,\n",
    "#        \"last_run\": 10\n",
    "#    },\n",
    "#    \"dev\": {\n",
    "#        \"participant_list\": [\"CSI1\", \"CSI2\", \"CSI3\"],\n",
    "#        \"start_sess\": 14,\n",
    "#        \"last_sess\": 15,\n",
    "#        \"start_run\": 1,\n",
    "#        \"last_run\": 10\n",
    "#    }\n",
    "#}\n",
    "\n",
    "data_split = {\n",
    "    \"train\": {\n",
    "        \"participant_list\": [\"CSI1\"],\n",
    "        \"start_sess\": 1,\n",
    "        \"last_sess\": 3,\n",
    "        \"start_run\": 1,\n",
    "        \"last_run\": 4\n",
    "    },\n",
    "    \"dev\": {\n",
    "        \"participant_list\": [\"CSI1\"],\n",
    "        \"start_sess\": 14,\n",
    "        \"last_sess\": 15,\n",
    "        \"start_run\": 1,\n",
    "        \"last_run\": 2\n",
    "    }\n",
    "}\n",
    "classes = {'ImageNet': 0, 'COCO': 1, 'Scene': 2}\n",
    "\n",
    "# Get list of stimuli pictures shown in each session in each run\n",
    "for data_type, items in data_split.items():\n",
    "    stList[data_type] = {}\n",
    "    for participant in items['participant_list']:\n",
    "        \n",
    "        # CS1 file are missing 1 after CSI\n",
    "        if participant == \"CSI1\":\n",
    "            CSI = \"CSI\"\n",
    "        else:\n",
    "            CSI = participant\n",
    "        \n",
    "        stList[data_type][participant] = {}\n",
    "        for sNum in range(items['start_sess'], items['last_sess']):\n",
    "            sSes = \"sess\" + str(sNum).zfill(2)\n",
    "            stList[data_type][participant][sSes] = {}\n",
    "            for rNum in range(items['start_run'], items['last_run']):\n",
    "                sRun = \"run\" + str(rNum).zfill(2)\n",
    "                dir_path = os.path.join(\"images\",\"BOLD5000_Stimuli\", \"Stimuli_Presentation_Lists\",participant, participant + \"_\" + sSes)\n",
    "                #print(stimulusDirPath)\n",
    "                stimulusListFilename = os.path.join(dir_path, \"_\".join([CSI, sSes, sRun]) + \".txt\")\n",
    "                #print(stimulusListFilename)\n",
    "                with open(stimulusListFilename) as f:\n",
    "                    stList[data_type][participant][sSes][sRun] = f.read().splitlines() \n",
    "\n",
    "            \n",
    "x_images_path = {}\n",
    "y_labels = {}\n",
    "for data_type, participantDict in stList.items():\n",
    "    x_images_path[data_type] = {}\n",
    "    y_labels[data_type] = {}\n",
    "    for participant, sessDict in participantDict.items(): \n",
    "        x_images_path[data_type][participant] = {}\n",
    "        y_labels[data_type][participant] = {}\n",
    "        for sess, runDict in sessDict.items():\n",
    "            x_images_path[data_type][participant][sess] = {}\n",
    "            y_labels[data_type][participant][sess] = {}\n",
    "            for run, imageList in runDict.items():\n",
    "                x_images_path[data_type][participant][sess][run] = []\n",
    "                y_labels[data_type][participant][sess][run] = []\n",
    "                #print(\"sess: %s, run: %s\" %(sess, run))\n",
    "                labelList = []\n",
    "                for imageFileName in imageList:\n",
    "                    for (currDir, _, fileList) in os.walk(stimulusDirPath):\n",
    "                        currBaseDir = os.path.basename(currDir)\n",
    "                        for filename in fileList:\n",
    "                            if filename in imageFileName:\n",
    "                                fullFilename = os.path.join(currDir, filename)\n",
    "                                x_images_path[data_type][participant][sess][run].append(fullFilename)\n",
    "                                # using directory path to determine class\n",
    "                                labelList.append(classes.get(currDir.split('/')[-1]))\n",
    "                                break\n",
    "        \n",
    "                y_labels[data_type][participant][sess][run] = np.reshape(np.asarray(labelList), (1, -1))\n",
    "\n",
    "# Todo: normalize data\n",
    "# x_train / 255.0, x_val/255.0, x_train/255.0\n",
    "\n",
    "#print(x_images_path)\n",
    "#print(y_labels[\"train\"][\"CSI1\"]['sess01']['run01'].shape)\n",
    "#print(y_labels[\"dev\"][\"CSI3\"]['sess01']['run01'].shape)\n",
    "#print(len(x_images_path[\"train\"][\"CSI1\"]['sess01']['run02']))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess \n",
    "Compute feature vectors using pretrained imagenet-vgg-verydeep model\n",
    "\n",
    "Feature vectors saved in file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = 'avgpool5'\n",
    "stimuli_features_dir = 'stimulifeatures'\n",
    "def unrollContentOutput(cOutput):\n",
    "    m, n_H, n_W, n_C = cOutput.shape\n",
    "    output = np.transpose(np.reshape(cOutput, (n_H * n_W, n_C)))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start time: %s\" % datetime.now().strftime('%Y-%m-%dT%H:%M:%S'))\n",
    "\n",
    "\n",
    "!mkdir -p stimulifeatures\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#sess = tf.InteractiveSession()\n",
    "#precompute content vectors from presented stimuli\n",
    "#content_layer = 'conv4_2'\n",
    "with tf.Session() as ts:\n",
    "    vmodel = load_vgg_model(\"imagenet-vgg-verydeep-19.mat\")\n",
    "    for data_type, participantDict in x_images_path.items():\n",
    "        for participant, sessDict in participantDict.items():\n",
    "            for sess, runDict in sessDict.items():\n",
    "                for run, imageList in runDict.items():\n",
    "                    #x_content = {sess: {run: []}}\n",
    "                    file_path= os.path.join(stimuli_features_dir, \"_\".join([participant, sess, run]) + \".npy\")\n",
    "                    if os.path.exists(file_path):\n",
    "                        #print already computed, skip\n",
    "                        continue\n",
    "\n",
    "                    print(\"file_path: %s\" % file_path)\n",
    "                    print(\"participant: %s, sess: %s, run: %s\" % (participant, sess, run))\n",
    "                    contentList = []\n",
    "                    for img_path in imageList:\n",
    "                        #stImage = imread(cImage)\n",
    "                        img = image.load_img(img_path, target_size=(375, 375))\n",
    "                        x = image.img_to_array(img)\n",
    "                        x = np.expand_dims(x, axis=0)\n",
    "                        x = preprocess_input(x)\n",
    "                        #print(\"img_path: %s\" % img_path)\n",
    "                        #print('Input image shape:', x.shape)\n",
    "                        #img_array = img_to_array(img)\n",
    "                        #stImage = imageio.imread(img_path)\n",
    "                        #print(\"img_path: %s\" % img_path)\n",
    "                        #print(stImage.shape)\n",
    "                        #stImage = reshape_and_normalize_image(stImage)\n",
    "                        #stImage = np.reshape(stImage, (1, 375, 375, 3))\n",
    "                        ts.run(vmodel['input'].assign(x))\n",
    "                        #a_C = sess.run(vmodel)\n",
    "                        out = vmodel[content_layer]\n",
    "                        contentOut = ts.run(out)\n",
    "                        contentList.append(unrollContentOutput(contentOut))\n",
    "            \n",
    "                    #x_content[sess][run] = np.asarray(contentList)\n",
    "                    contentArray = np.asarray(contentList)\n",
    "                    # shape is (35, 512, 144): num of pictures, channels, width*height\n",
    "                    #print(x_content[sess][run].shape)\n",
    "                    #x_content[sess][run].append(unrollContentOutput(contentOut))\n",
    "        \n",
    "                    #np.save(file_path, x_content)\n",
    "                    np.save(file_path, contentArray)\n",
    "                    #del x_content\n",
    "\n",
    "print('done')\n",
    "print(\"end time: %s\" % datetime.now().strftime('%Y-%m-%dT%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as ts:\n",
    "    vmodel = load_vgg_model(\"imagenet-vgg-verydeep-19.mat\")\n",
    "    img_path = './images/BOLD5000_Stimuli/Scene_Stimuli/Presented_Stimuli/ImageNet/n01833805_1411.JPEG'\n",
    "    img = image.load_img(img_path, target_size=(375, 375))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    ts.run(vmodel['input'].assign(x))\n",
    "    out = vmodel[content_layer]\n",
    "    predictContentOut = ts.run(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "VERSION = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "file_path = os.path.join('stimulifeatures', 'CSI2_sess01_run01.npy')\n",
    "\n",
    "x_content = np.load(file_path, allow_pickle=True)\n",
    "print(x_content.shape)\n",
    "\n",
    "def dnn_classifier(input_shape, num_classes):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Flatten()(X_input)\n",
    "    X = Dense(64, activation='tanh')(X)\n",
    "    #X = Dense(16, activation='tanh')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(num_classes, activation='softmax')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='dnn_classifier')\n",
    "    return model\n",
    "\n",
    "def dnn_gap_classifier(input_shape, num_classes):\n",
    "    X_input = Input(input_shape)\n",
    "    X = GlobalAveragePooling1D(data_format='channels_first')(X_input)\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    #X = Activation('relu')(X)\n",
    "    #X = Dropout(0.2)(X)\n",
    "    X = Dense(num_classes, activation='softmax')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='dnn_classifier')\n",
    "    return model\n",
    "\n",
    "\n",
    "def auto_encoder(input_shape, encoding_dim):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Dense(encoding_dim, activation='relu')(X_input)\n",
    "    model = Model(inputs = X_input, outputs = X, name='dnn_classifier')\n",
    "    return model\n",
    "\n",
    "def cnn_classifier(input_shape, num_classes):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Conv2D(32, (3, 3), padding='same')(X_input)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(32, (3, 3))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "    X = Conv2D(64, (3, 3), padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, (3, 3))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dense(num_classes)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='cnn_classifier')\n",
    "    return model\n",
    "\n",
    "#model = tf.keras.models.Sequential([\n",
    "#    tf.keras.layers.Flatten(input_shape=[512, 144]),\n",
    "#    tf.keras.layers.Dense(128, activation='relu'),\n",
    "#    tf.keras.layers.Dropout(0.2),\n",
    "#    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "#])\n",
    "\n",
    "#model = tf.keras.models.Sequential([\n",
    "#    tf.keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "#                 input_shape=x_train.shape[1:]),\n",
    "#    tf.keras.layers.Activation('relu'),\n",
    "#    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "#    tf.keras.layers.Activation('relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#    tf.keras.layers.Dropout(0.25),\n",
    "#    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "#    tf.keras.layers.Activation('relu'),\n",
    "#    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "#    tf.keras.layers.Activation('relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#    tf.keras.layers.Dropout(0.25),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(512),\n",
    "#    tf.keras.layers.Activation('relu'),\n",
    "#    tf.keras.layers.Dense(num_classes),\n",
    "#    tf.keras.layers.Activation('softmax')\n",
    "#])\n",
    "\n",
    "\n",
    "#input_shape=[512, 144]\n",
    "input_shape = x_content.shape[1:]\n",
    "print(input_shape)\n",
    "#model = dnn_classifier(input_shape, num_classes)\n",
    "model = dnn_gap_classifier(input_shape, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadFeatureVector(file_path):\n",
    "    return np.load(file_path, allow_pickle=True)\n",
    "    \n",
    "def featureVectorLoader(data_split, data_type):\n",
    "    #every file has 35 feature vectors (one batch)   \n",
    "    x_images = data_split.get(data_type, None)\n",
    "    while True:\n",
    "        for participant, sessDict in x_images.items():\n",
    "            for sess, runDict in sessDict.items():\n",
    "                for run in runDict.keys():\n",
    "                    file_path= os.path.join(stimuli_features_dir, \"_\".join([participant, sess, run]) + \".npy\")\n",
    "                    X = loadFeatureVector(file_path)\n",
    "                    Y = utils.to_categorical(np.transpose(y_labels[data_type][participant][sess][run]))\n",
    "                    yield (X,Y)\n",
    "\n",
    "EPOCHS=20\n",
    "#callbacks\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=4),\n",
    "             ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "\n",
    "#callbacks = [ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#train_history = model.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=35, validation_data=(x_test, y_test))\n",
    "#train_history = model.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=35, validation_data=(x_test, y_test))\n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path), steps_per_epoch=5, epochs=EPOCHS, callbacks=callbacks) \n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path), steps_per_epoch=5, epochs=EPOCHS, callbacks=callbacks, validation_data=(x_test, y_test)) \n",
    "\n",
    "#steps_per_epoch = (last_sess - 1) * (last_run - 1)\n",
    "\n",
    "numberOfSessions = data_split[\"train\"][\"last_sess\"] - data_split[\"train\"][\"start_sess\"]\n",
    "numberOfRuns = data_split[\"train\"][\"last_run\"] - data_split[\"train\"][\"start_run\"]\n",
    "numberOfParticipants = len(data_split[\"train\"][\"participant_list\"])\n",
    "steps_per_epoch = numberOfSessions * numberOfRuns * numberOfParticipants\n",
    "\n",
    "numberOfSessions = data_split[\"dev\"][\"last_sess\"] - data_split[\"dev\"][\"start_sess\"]\n",
    "numberOfRuns = data_split[\"dev\"][\"last_run\"] - data_split[\"dev\"][\"start_run\"]\n",
    "numberOfParticipants = len(data_split[\"dev\"][\"participant_list\"])\n",
    "validation_steps = numberOfSessions * numberOfRuns * numberOfParticipants\n",
    "\n",
    "print(\"Total number of training examples: %s\" % (steps_per_epoch * 37))\n",
    "print(\"Total number of dev examples: %s\" % (validation_steps * 37))\n",
    "\n",
    "print(\"steps_per_epoch: %s\" % steps_per_epoch)\n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path), steps_per_epoch=350, epochs=EPOCHS, validation_data=(x_test, y_test)) \n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path, \"train\"), steps_per_epoch=350, epochs=EPOCHS, validation_data=featureVectorLoader(x_images_path, \"train\"), validation_steps=350) \n",
    "train_history = model.fit_generator(featureVectorLoader(x_images_path, \"train\"), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
    "                                    callbacks=callbacks, validation_data=featureVectorLoader(x_images_path, \"dev\"),\n",
    "                                    validation_steps=validation_steps) \n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path, \"train\"), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
    "#                                    callbacks=callbacks, validation_data=(x_dev, y_dev))\n",
    "\n",
    "\n",
    "loss = train_history.history['loss']\n",
    "val_loss = train_history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "new_model = load_model('weights.20.h5')\n",
    "new_model.summary()\n",
    "print(new_model.get_weights()[0].shape)\n",
    "print(new_model.get_weights()[1].shape)\n",
    "print(new_model.get_weights()[2].shape)\n",
    "print(new_model.get_weights()[3].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N=50\n",
    "arr1 = new_model.get_weights()[2][:,0]\n",
    "indices1 = np.argsort(arr1, axis=0)[-N:]\n",
    "arr2 = new_model.get_weights()[2][:,1]\n",
    "indices2 = np.argsort(arr2, axis=0)[-N:]\n",
    "arr3 = new_model.get_weights()[2][:,2]\n",
    "indices3 = np.argsort(arr3, axis=0)[-N:]\n",
    "#\n",
    "print(indices1)\n",
    "print(indices2)\n",
    "print(indices3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "arr = new_model.get_weights()[0]\n",
    "N=20\n",
    "filter_select = []\n",
    "for index_list in [indices1, indices2, indices3]:\n",
    "    all_ind = []\n",
    "    for index in index_list:\n",
    "        indices = np.argsort(arr, axis=0)[-N:, index]\n",
    "        sort_ind = np.sort(indices, axis=-1)\n",
    "        all_ind.extend(list(sort_ind))\n",
    "        #print(sort_ind)\n",
    "        #plt.plot(sort_ind)\n",
    "    a_ind = [key for key,_ in Counter(all_ind).most_common()][0:10]\n",
    "    print(a_ind)\n",
    "    filter_select.extend([item for item in a_ind if item not in filter_select])\n",
    "    \n",
    "print(filter_select)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nibabel\n",
    "import nibabel as nib\n",
    "import re\n",
    "fmri_data_dir = '/home/ubuntu/cs230Project/dataset/ds001499-download'\n",
    "stimuli_features_dir = 'stimulifeatures'\n",
    "fmriRegex = re.compile(r'^(.*?)_sess(.*?)_run(.*?).npy$')\n",
    "\n",
    "# At the beginning and end of each run, a fixation cross was shown for 6 sec (3TORs) and\n",
    "# 12 sec (6TORs), respectively. hence stIndex goes from 3:-6\n",
    "# 37 images shows in each run >> 185 TOR\n",
    "# Each image was presented for 1 sec followed by a 9 sec fixation cross (5TORs)\n",
    "# For each stimuls, average assocated 5 TORs and map them\n",
    "def loadFmriData(file_path):\n",
    "    x_train = []\n",
    "    epi_img = nib.load(file_path)\n",
    "    img_data = epi_img.get_fdata()\n",
    "    for stIndex in range(4,  img_data.shape[-1] - 5, 5):\n",
    "        x_train.append(np.mean(img_data[:,:,:,stIndex:stIndex+5], axis=-1))\n",
    "\n",
    "    x = np.asarray(x_train)\n",
    "    #(37, 106, 106, 69)\n",
    "    return x\n",
    "\n",
    "def loadFmriLstmData(file_path):\n",
    "    x_train = []\n",
    "    epi_img = nib.load(file_path)\n",
    "    img_data = epi_img.get_fdata()\n",
    "    for stIndex in range(4,  img_data.shape[-1] - 5, 5):\n",
    "        x_train.append(np.mean(img_data[:,:,:,stIndex:stIndex+5], axis=-1))\n",
    "\n",
    "    x = np.asarray(x_train)\n",
    "    #(37, 106, 106, 69) > (37, 69, 106*106)\n",
    "    x = np.swapaxes(np.reshape(x, (37, -1, 69)), 1, 2)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def loadFilterVector(file_path, filterNumList):\n",
    "    all_features = np.load(file_path, allow_pickle=True)\n",
    "    features = []\n",
    "    for filterNum in filterNumList:\n",
    "        features.append(all_features[:, filterNum, :].T)\n",
    "    \n",
    "    ft = np.asarray(features)\n",
    "    return ft.reshape(-1, 37).T\n",
    "\n",
    "filterNumList = [452, 209, 327, 377, 33, 16, 433, 19, 66, 467]\n",
    "data_split = x_images_path\n",
    "data_type = \"train\"\n",
    "x_images = data_split.get(data_type, None)\n",
    "for participant, sessDict in x_images.items():\n",
    "    for sess, runDict in sessDict.items():\n",
    "        for run in runDict.keys():\n",
    "            #fmri_data_path = os.path.join(fmri_data_dir, \"sub-%s\" % participant, \"sess\" \"_\".join([participant, sess, run]) + \".npy\")\n",
    "            feature_file_name = \"_\".join([participant, sess, run]) + \".npy\"\n",
    "            #sub-CSI3/ses-01/func\n",
    "            # sub-CSI3_ses-09_task-5000scenes_run-05_bold.nii.gz\n",
    "            match = fmriRegex.match(feature_file_name)\n",
    "            if match:\n",
    "                  fmri_file_name = \"sub-%s_ses-%s_task-5000scenes_run-%s_bold.nii.gz\" % ( match.group(1), match.group(2), match.group(3))\n",
    "                  fmri_data_path = os.path.join(fmri_data_dir, \"sub-%s\" % match.group(1), \"ses-%s\" % match.group(2), \"func\", fmri_file_name)\n",
    "                  print(fmri_data_path)\n",
    "                \n",
    "            feature_vector_path= os.path.join(stimuli_features_dir, feature_file_name)\n",
    "            X = loadFmriLstmData(fmri_data_path)\n",
    "            Y = loadFilterVector(feature_vector_path, filterNumList)\n",
    "            print(X.shape)\n",
    "            print(Y.shape)\n",
    "            break\n",
    "\n",
    "                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROI_list = [\n",
    "    'X_LHPPA.npy', #(19380, 5, 100)\n",
    "    'X_RHLOC.npy', #(19380, 5, 170)\n",
    "    'X_LHLOC.npy', #(19380, 5, 130)\n",
    "    'X_RHEarlyVis.npy', #(19380, 5, 220)\n",
    "    'X_RHRSC.npy', #(19380, 5, 100)\n",
    "    'X_RHOPA.npy', #(19380, 5, 80)\n",
    "    'X_RHPPA.npy', #(19380, 5, 140)\n",
    "    'X_LHEarlyVis.npy', #(19380, 5, 190)\n",
    "    'X_LHRSC.npy', #(19380, 5, 30)\n",
    "    'X_LHOPA.npy', #(19380, 5, 70)\n",
    "]\n",
    "\n",
    "#x_all (19380, 5, 1230)\n",
    "#y_all shape (19380, 17)\n",
    "\n",
    "#one way is to concatenate last dimenesion and just use 5 time series\n",
    "# so lstm input would be \n",
    "# other way is to train each roi seperately to encode to feature vector. and then inout feature vectoers to classify\n",
    "# or input roi as LSTM nodes to get one feature vector\n",
    "\n",
    "train_folder = '/home/ubuntu/cs230Project/dataset/traindata'\n",
    "array_list = []\n",
    "for roc_file in ROI_list:\n",
    "    xt_file_path = os.path.join(train_folder, roc_file)\n",
    "    xtrain_n = np.load(xt_file_path)\n",
    "    array_list.append(xtrain_n)\n",
    "    #print(xtrain_n.shape)\n",
    "\n",
    "#all_x = np.asarray(array_list)\n",
    "#print(all_x.shape)\n",
    "x_all = np.dstack(array_list)\n",
    "print(x_all.shape)\n",
    "\n",
    "yt_file_path = os.path.join(train_folder, 'Yreal_all.npy')\n",
    "y_all = np.load(yt_file_path)\n",
    "\n",
    "num_classes = y_all.shape[1]\n",
    "\n",
    "x_train = x_all[0:18380, :, :]\n",
    "y_train = y_all[0:18380, :]\n",
    "x_test = x_all[18380:, :, :]\n",
    "y_test = y_all[18380:, :]\n",
    "\n",
    "def classifer_lstm(input_shape, num_classes):\n",
    "    X_input = Input(input_shape)\n",
    "    X = LSTM(512, dropout=0.2)(X_input)\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(num_classes, activation = \"softmax\")(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='auto_encoder_lstm')\n",
    "    return model\n",
    "\n",
    "Tx = x_train.shape[1]\n",
    "Voxels = x_train.shape[2]\n",
    "classifier_lstm = classifer_lstm((Tx, Voxels), num_classes)\n",
    "\n",
    "EPOCHS=100\n",
    "#callbacks\n",
    "#callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "#             ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "\n",
    "#callbacks = [ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "classifier_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train_history = classifier_lstm.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=35, validation_data=(x_test, y_test))\n",
    "train_history = classifier_lstm.fit(x=x_train, y=y_train, epochs=EPOCHS, batch_size=35, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array_list[0].shape)\n",
    "print(array_list[1].shape)\n",
    "test = np.dstack((array_list[0],array_list[1]))\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single layer neural network (one network per filter) to map fmri data to above filters\n",
    "# input: X of shape (106, 106, 69, 194) \n",
    "# output: Y of shape (144, 1) image features on specific filters\n",
    "fmriRegex = re.compile(r'^(.*?)_sess(.*?)_run(.*?).npy$')\n",
    "\n",
    "fmri_data_dir = '/home/ubuntu/cs230Project/dataset/ds001499-download'\n",
    "stimuli_features_dir = 'stimulifeatures'\n",
    "\n",
    "def loadFilterVector(file_path, filterNumList):\n",
    "    all_features = np.load(file_path, allow_pickle=True)\n",
    "    #features = []\n",
    "    #for filterNum in filterNumList:\n",
    "    #    features.append(all_features[:, filterNum, :].T)\n",
    "    \n",
    "    #ft = np.asarray(features)\n",
    "    #return ft.reshape(-1, 37).T\n",
    "    #return all_features[:, 377, :]\n",
    "    feat_sel = all_features[:, filterNumList, :]\n",
    "    sel_shape = feat_sel.shape[0]\n",
    "    return feat_sel.reshape(sel_shape, -1)\n",
    "\n",
    "# At the beginning and end of each run, a fixation cross was shown for 6 sec (3TORs) and\n",
    "# 12 sec (6TORs), respectively. hence stIndex goes from 3:-6\n",
    "# 37 images shows in each run >> 185 TOR\n",
    "# Each image was presented for 1 sec followed by a 9 sec fixation cross (5TORs)\n",
    "# For each stimuls, average assocated 5 TORs and map them\n",
    "def loadFmriData(file_path):\n",
    "    x_train = []\n",
    "    epi_img = nib.load(file_path)\n",
    "    img_data = epi_img.get_fdata()\n",
    "    for stIndex in range(4, img_data.shape[-1] - 5, 5):\n",
    "        #x_train.append(np.mean(img_data[:,:,:,stIndex:stIndex+5], axis=-1))\n",
    "        x_train.append((img_data[:,:,:,stIndex+3]))\n",
    "\n",
    "    x = np.asarray(x_train)\n",
    "    return x\n",
    "\n",
    "def loadFmriLstmData(file_path):\n",
    "    x_train = []\n",
    "    epi_img = nib.load(file_path)\n",
    "    img_data = epi_img.get_fdata()\n",
    "    for stIndex in range(4,  img_data.shape[-1] - 5, 5):\n",
    "        x_train.append(np.mean(img_data[:,:,:,stIndex:stIndex+5], axis=-1))\n",
    "\n",
    "    x = np.asarray(x_train)\n",
    "    #(37, 106, 106, 69) > (37, 69, 106*106)\n",
    "    x = np.swapaxes(np.reshape(x, (37, -1, 69)), 1, 2)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def featureVectorLoader(data_split, data_type, filterNum):\n",
    "    #every file has 35 feature vectors (one batch)\n",
    "    L = len(fileList)   \n",
    "    x_images = data_split.get(data_type, None)\n",
    "    while True:\n",
    "        for participant, sessDict in x_images.items():\n",
    "            for sess, runDict in sessDict.items():\n",
    "                for run in runDict.keys():\n",
    "                    #fmri_data_path = os.path.join(fmri_data_dir, \"sub-%s\" % participant, \"sess\" \"_\".join([participant, sess, run]) + \".npy\")\n",
    "                    feature_file_name = \"_\".join([participant, sess, run]) + \".npy\"\n",
    "                    #sub-CSI3/ses-01/func\n",
    "                    # sub-CSI3_ses-09_task-5000scenes_run-05_bold.nii.gz\n",
    "                    match = fmriRegex.match(feature_file_name)\n",
    "                    if match:\n",
    "                        fmri_file_name = \"sub-%s_ses-%s_task-5000scenes_run-%s_bold.nii.gz\" % ( match.group(1), match.group(2), match.group(3))\n",
    "                        fmri_data_path = os.path.join(fmri_data_dir, \"sub-%s\" % match.group(1), \"ses-%s\" % match.group(2), \"func\", fmri_file_name)\n",
    "                \n",
    "                    feature_vector_path= os.path.join(stimuli_features_dir, feature_file_name)\n",
    "                    X = loadFmriLstmData(fmri_data_path)\n",
    "                    Y = loadFilterVector(feature_vector_path, filterNum)\n",
    "                    yield (X,Y)\n",
    "\n",
    "\n",
    "# for each y, we have \n",
    "def auto_encoder(input_shape, encoding_dim):\n",
    "    X_input = Input(input_shape)\n",
    "    #X = Conv2D(2, (5,5), activation='relu')(X_input)\n",
    "    #X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    #X = Dropout(0.25)(X)\n",
    "    X = Conv2D(4, (1,1), activation='tanh')(X_input)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "    X = Dense(encoding_dim, activation='relu')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='auto_encoder')\n",
    "    return model\n",
    "\n",
    "# for each y, we have \n",
    "def auto_encoder_lstm(input_shape, encoding_dim):\n",
    "    X_input = Input(input_shape)\n",
    "    #X = LSTM(units = 128, return_sequences = True)(X_input)\n",
    "    #LSTM(128, dropout=0.2, recurrent_dropout=0.2)\n",
    "    X = LSTM(128)(X_input)\n",
    "    #X = TimeDistributed(Dense(encoding_dim, activation = \"sigmoid\"))(X)\n",
    "    X = Dense(encoding_dim, activation = \"sigmoid\")(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='auto_encoder_lstm')\n",
    "    return model\n",
    "\n",
    "EPOCHS = 100\n",
    "filterNumList = [452, 209, 327, 377, 33, 16, 433, 19, 66, 467]\n",
    "#filterNumList = [377]\n",
    "numberOfSessions = data_split[\"train\"][\"last_sess\"] - data_split[\"train\"][\"start_sess\"]\n",
    "numberOfRuns = data_split[\"train\"][\"last_run\"] - data_split[\"train\"][\"start_run\"]\n",
    "numberOfParticipants = len(data_split[\"train\"][\"participant_list\"])\n",
    "steps_per_epoch = numberOfSessions * numberOfRuns * numberOfParticipants\n",
    "\n",
    "numberOfSessions = data_split[\"dev\"][\"last_sess\"] - data_split[\"dev\"][\"start_sess\"]\n",
    "numberOfRuns = data_split[\"dev\"][\"last_run\"] - data_split[\"dev\"][\"start_run\"]\n",
    "numberOfParticipants = len(data_split[\"dev\"][\"participant_list\"])\n",
    "validation_steps = numberOfSessions * numberOfRuns * numberOfParticipants\n",
    "\n",
    "encoder_model = auto_encoder_lstm((69, 106*106), len(filterNumList)*144)\n",
    "#encoder_model = auto_encoder((106,106,69), len(filterNumList)*144)\n",
    "#cosine_proximity\n",
    "#encoder_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "encoder_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "train_history = encoder_model.fit_generator(featureVectorLoader(x_images_path, \"train\", filterNumList), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
    "                                    validation_data=featureVectorLoader(x_images_path, \"dev\", filterNumList),\n",
    "                                    validation_steps=validation_steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = unrollContentOutput(predictContentOut)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print('Input image shape:', x.shape)\n",
    "print(model.predict(x))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed fmri data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "def dnn_classifier(input_shape, num_classes):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Flatten()(X_input)\n",
    "    X = Dense(512, activation='tanh')(X)\n",
    "    X = Dense(128, activation='tanh')(X)\n",
    "    X = Dense(num_classes, activation='softmax')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='dnn_classifier')\n",
    "    return model\n",
    "\n",
    "input_shape = x_content.shape[1:]\n",
    "model2 = dnn_classifier(input_shape, num_classes)\n",
    "\n",
    "EPOCHS=100\n",
    "#callbacks\n",
    "#callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "#             ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train_history = model.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=35, validation_data=(x_test, y_test))\n",
    "#train_history = model.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=35, validation_data=(x_test, y_test))\n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path), steps_per_epoch=5, epochs=EPOCHS, callbacks=callbacks) \n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path), steps_per_epoch=5, epochs=EPOCHS, callbacks=callbacks, validation_data=(x_test, y_test)) \n",
    "\n",
    "#steps_per_epoch = (last_sess - 1) * (last_run - 1)\n",
    "\n",
    "numberOfSessions = data_split[\"train\"][\"last_sess\"] - data_split[\"train\"][\"start_sess\"]\n",
    "numberOfRuns = data_split[\"train\"][\"last_run\"] - data_split[\"train\"][\"start_run\"]\n",
    "numberOfParticipants = len(data_split[\"train\"][\"participant_list\"])\n",
    "steps_per_epoch = numberOfSessions * numberOfRuns * numberOfParticipants\n",
    "\n",
    "numberOfSessions = data_split[\"dev\"][\"last_sess\"] - data_split[\"dev\"][\"start_sess\"]\n",
    "numberOfRuns = data_split[\"dev\"][\"last_run\"] - data_split[\"dev\"][\"start_run\"]\n",
    "numberOfParticipants = len(data_split[\"dev\"][\"participant_list\"])\n",
    "validation_steps = numberOfSessions * numberOfRuns * numberOfParticipants\n",
    "\n",
    "\n",
    "print(\"Total number of training examples: %s\" % (steps_per_epoch * 37))\n",
    "print(\"Total number of dev examples: %s\" % (validation_steps * 37))\n",
    "\n",
    "print(\"steps_per_epoch: %s\" % steps_per_epoch)\n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path), steps_per_epoch=350, epochs=EPOCHS, validation_data=(x_test, y_test)) \n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path, \"train\"), steps_per_epoch=350, epochs=EPOCHS, validation_data=featureVectorLoader(x_images_path, \"train\"), validation_steps=350) \n",
    "#train_history = model.fit_generator(featureVectorLoader(x_images_path, \"train\"), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
    "#                                    callbacks=callbacks, validation_data=featureVectorLoader(x_images_path, \"dev\"),\n",
    "#                                    validation_steps=validation_steps) \n",
    "train_history = model2.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=35, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss = train_history.history['loss']\n",
    "val_loss = train_history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
