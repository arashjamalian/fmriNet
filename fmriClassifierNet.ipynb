{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from matplotlib.pyplot import imread, imshow\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "#import imageio\n",
    "from nst_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "#%aimport \n",
    "\n",
    "SEED=1\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "K.clear_session()\n",
    "#K.set_image_data_format('channels_last')\n",
    "#K.set_learning_phase(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 35)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "sCS = \"CSI2\"\n",
    "sesNum = \"01\"\n",
    "runNum = \"02\"\n",
    "sSes = \"sess\" + sesNum\n",
    "sRun = \"run\" + runNum\n",
    "\n",
    "stList = {}\n",
    "last_sess = 2 # 15\n",
    "last_run = 9 # 9\n",
    "\n",
    "\n",
    "for sNum in range(1, last_sess):\n",
    "    sSes = \"sess\" + str(sNum).zfill(2)\n",
    "    stList[sSes] = {}\n",
    "    for rNum in range(1, 9):\n",
    "        sRun = \"run\" + str(rNum).zfill(2)\n",
    "        stimulusDirPath = os.path.join(\"images\",\"BOLD5000_Stimuli\", \"Stimuli_Presentation_Lists\",sCS, sCS + \"_\" + sSes)\n",
    "        #print(stimulusDirPath)\n",
    "        stimulusListFilename = os.path.join(stimulusDirPath, \"_\".join([sCS, sSes, sRun]) + \".txt\")\n",
    "        #print(stimulusListFilename)\n",
    "        with open(stimulusListFilename) as f:\n",
    "            stList[sSes][sRun] = f.read().splitlines()\n",
    "\n",
    "\n",
    "# Takes ~1 min\n",
    "stimulusDirPath = os.path.join('images', 'BOLD5000_Stimuli', 'Scene_Stimuli', 'Presented_Stimuli')\n",
    "\n",
    "x_images_path = {}\n",
    "y_labels = {}\n",
    "classes = {'ImageNet': 0, 'COCO': 1, 'Scene': 2}\n",
    "for sess in stList:\n",
    "    x_images_path[sess] = {}\n",
    "    y_labels[sess] = {}\n",
    "    for run in stList[sess]:\n",
    "        x_images_path[sess][run] = []\n",
    "        y_labels[sess][run] = []\n",
    "        #print(\"sess: %s, run: %s\" %(sess, run))\n",
    "        labelList = []\n",
    "        for imageFileName in stList[sess][run]:\n",
    "            for (currDir, _, fileList) in os.walk(stimulusDirPath):\n",
    "                currBaseDir = os.path.basename(currDir)\n",
    "                for filename in fileList:\n",
    "                    if filename == imageFileName:\n",
    "                        fullFilename = os.path.join(currDir, filename)\n",
    "                        #print(currDir)\n",
    "                        x_images_path[sess][run].append(fullFilename)\n",
    "                        # using directory path to determine class\n",
    "                        labelList.append(classes.get(currDir.split('/')[-1]))\n",
    "\n",
    "        y_labels[sess][run] = np.reshape(np.asarray(labelList), (1, -1))\n",
    "\n",
    "#print(x_images_path)\n",
    "print(y_labels['sess01']['run01'].shape)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 35)\n",
      "[[0 0 1 1 1 2 1 0 1 0 1 2 1 0 0 2 1 2 1 0 0 2 0 1 1 0 2 2 0 1 1 0 1 0 0]]\n",
      "35\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#print(x_images_path)\n",
    "print(y_labels['sess01']['run01'].shape)\n",
    "print(y_labels['sess01']['run01'])\n",
    "print(len(x_images_path['sess01']['run08']))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1028 02:32:37.143805 139759358707456 deprecation_wrapper.py:119] From /home/ubuntu/fmriNet/nst_utils.py:127: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: stimulifeatures/CSI2_sess01_run01.npy\n",
      "sess: sess01, run: run01\n",
      "file_path: stimulifeatures/CSI2_sess01_run02.npy\n",
      "sess: sess01, run: run02\n",
      "file_path: stimulifeatures/CSI2_sess01_run03.npy\n",
      "sess: sess01, run: run03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-db847315db1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m#a_C = sess.run(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontent_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mcontentOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mcontentList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrollContentOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontentOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#print(x_images_path[\"sess04\"][\"run07\"])\n",
    "def unrollContentOutput(cOutput):\n",
    "    m, n_H, n_W, n_C = cOutput.shape\n",
    "    output = np.transpose(np.reshape(cOutput, (n_H * n_W, n_C)))\n",
    "    return output\n",
    "\n",
    "!mkdir -p stimulifeatures\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#sess = tf.InteractiveSession()\n",
    "#precompute content vectors from presented stimuli\n",
    "#content_layer = 'conv4_2'\n",
    "content_layer = 'avgpool5'\n",
    "stimuli_features_dir = 'stimulifeatures'\n",
    "with tf.Session() as ts:\n",
    "    model = load_vgg_model(\"imagenet-vgg-verydeep-19.mat\")\n",
    "    for sess in x_images_path:\n",
    "        for run in x_images_path[sess]:\n",
    "            x_content = {sess: {run: []}}\n",
    "            file_path= os.path.join(stimuli_features_dir, \"_\".join([sCS, sess, run]) + \".npy\")\n",
    "            print(\"file_path: %s\" % file_path)\n",
    "            print(\"sess: %s, run: %s\" %(sess, run))\n",
    "            contentList = []\n",
    "            for img_path in x_images_path[sess][run]:\n",
    "                #stImage = imread(cImage)\n",
    "                img = image.load_img(img_path, target_size=(375, 375))\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "                #print(\"img_path: %s\" % img_path)\n",
    "                #print('Input image shape:', x.shape)\n",
    "                #img_array = img_to_array(img)\n",
    "                #stImage = imageio.imread(img_path)\n",
    "                #print(\"img_path: %s\" % img_path)\n",
    "                #print(stImage.shape)\n",
    "                #stImage = reshape_and_normalize_image(stImage)\n",
    "                #stImage = np.reshape(stImage, (1, 375, 375, 3))\n",
    "                ts.run(model['input'].assign(x))\n",
    "                #a_C = sess.run(model)\n",
    "                out = model[content_layer]\n",
    "                contentOut = ts.run(out)\n",
    "                contentList.append(unrollContentOutput(contentOut))\n",
    "            \n",
    "            x_content[sess][run] = np.asarray(contentList)\n",
    "            # shape is (35, 512, 144): num of pictures, channels, width*height\n",
    "            #print(x_content[sess][run].shape)\n",
    "            #x_content[sess][run].append(unrollContentOutput(contentOut))\n",
    "\n",
    "            np.save(file_path, x_content)\n",
    "            del x_content\n",
    "            \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 512, 144)\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join('stimulifeatures', 'CSI2_sess01_run01.npy')\n",
    "x_content = np.load(file_path, allow_pickle=True).item()\n",
    "print(x_content.get('sess01')['run01'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimulifeatures/CSI2_sess01_run01.npy\n",
      "stimulifeatures/CSI2_sess01_run02.npy\n",
      "(512, 144)\n",
      "(512, 144)\n",
      "(512, 144)\n",
      "(70, 512, 144)\n"
     ]
    }
   ],
   "source": [
    "# Generate training and test set\n",
    "# For milestone, first we try to train a classifier network using feature vectors from above\n",
    "stimuli_features_dir = 'stimulifeatures'\n",
    "#concatenate all feature vectors from all sessions/runs\n",
    "x_all_list = []\n",
    "for (currDir, _, fileList) in os.walk(stimuli_features_dir):\n",
    "    currBaseDir = os.path.basename(currDir)\n",
    "    for filename in fileList:\n",
    "        fullFilename = os.path.join(currDir, filename)\n",
    "        print(fullFilename)\n",
    "        x_content = np.load(fullFilename, allow_pickle=True).item()\n",
    "        for sess in x_content:\n",
    "            for run in x_content[sess]:\n",
    "                x_all_list.extend(x_content[sess][run])\n",
    "\n",
    "print(x_all_list[0].shape)\n",
    "print(x_all_list[1].shape)\n",
    "print(x_all_list[43].shape)\n",
    "x_all = np.asarray(x_all_list)\n",
    "print(x_all.shape)\n",
    "\n",
    "#for sess in x_images_path:\n",
    "#    for run in x_images_path[sess]:\n",
    "#        file_path = os.path.join('stimulifeatures', \"_\".join([sCS, sess, run]) + \".npy\")\n",
    "#        x_content = np.load(file_path)\n",
    "#        print(x_content.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for sess in x_images_path:\n",
    "#    for run in x_images_path[sess]:\n",
    "#        file_path = os.path.join('stimulifeatures', \"_\".join([sCS, sess, run]) + \".npy\")\n",
    "#        x_content = np.load(file_path)\n",
    "#        print(x_content.keys())\n",
    "            \n",
    "\n",
    "#print(x_content['sess01']['run01'][0].shape)\n",
    "#print(x_content['sess01']['run01'][3].shape)\n",
    "#print(y_labels['sess01']['run01'].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create train and test test\n",
    "x_all = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[512, 2209]),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# split train test set\n",
    "# del loaded data\n",
    "# assert on expected shape\n",
    "# assert x_train.shape == ()\n",
    "\n",
    "#K.set_image_date_format('channels_last')\n",
    "\n",
    "#mnist = tf.keras.datasets.mnist\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#x_val, x_test = np.split(x_test, 2)\n",
    "#y_val, y_test = np.split(y_test, 2)\n",
    "\n",
    "#x_train, x_val, x_test = x_train / 255.0, x_val/255.0, x_train/255.0\n",
    "#print(x_train.shape)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train_orig), (x_test_orig, y_test_orig) = cifar10.load_data()\n",
    "x_val, x_test = np.split(x_test_orig, 2)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = utils.to_categorical(y_train_orig, num_classes)\n",
    "y_test_1 = utils.to_categorical(y_test_orig, num_classes)\n",
    "\n",
    "#y_val, y_test = np.split(y_test_1, 2)\n",
    "del x_test_orig\n",
    "del y_test_orig\n",
    "del y_train_orig\n",
    "del y_test_1\n",
    "\n",
    "#x_train, x_val, x_test = x_train / 255.0, x_val/255.0, x_train/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(num_classes),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def classifer_cnn(input, name):\n",
    "#    X = \n",
    "#    X = Conv2D()\n",
    "#    return Model(input, X, name=name)\n",
    "#input_shape =(28, 28, 3)\n",
    "\n",
    "#model = tf.keras.models.Sequential([\n",
    "#    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "#                           activation='relu',\n",
    "#                           input_shape=input_shape),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(128, activation='relu'),\n",
    "#    tf.keras.layers.Dropout(0.2),\n",
    "#    tf.keras.layers.Dense(10, activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "#                 activation='relu',\n",
    "#                 input_shape=input_shape))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "#model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "!mkdir -p models\n",
    "#%notebook -e models/{VERSION}.ipynb\n",
    "\n",
    "#K.clear_session()\n",
    "#K.set_session(tf.Session(config=))\n",
    "#model = classifer_cnn(x_in, 'classifer_cnn')\n",
    "#model.save(f'models/{VERSION}.architecture.h5')\n",
    "#model.save('models/latest.architecture.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=40\n",
    "#K.set_image_date_format('channels_last')\n",
    "\n",
    "def scheduler(epoch):\n",
    "  if epoch < 10:\n",
    "    return 0.001\n",
    "  else:\n",
    "    return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "\n",
    "#callbacks\n",
    "#tensorboard = Tensorboard(log_di='logs/' + VERSION)\n",
    "#checkpoint_file_path = f'models/{VERSION}/{VERSION}.checkpoint.h5'\n",
    "checkpoint_file_path = 'weights.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_file_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2),\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                              patience=5, min_lr=0.001)\n",
    "#learning_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "#callbacks = [model_checkpoint, reduce_lr]\n",
    "#callbacks = [model_checkpoint, reduce_lr, learning_scheduler]\n",
    "#callbacks = [early_stopping, model_checkpoint]\n",
    "#callbacks = [early_stopping]\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "             ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1)]\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#train_history = model.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=256, validation_data=(x_val, y_val))\n",
    "train_history = model.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=256, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "#plotter.losses(history)\n",
    "loss = train_history.history['loss']\n",
    "val_loss = train_history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "#initial_epoch += EPOCHS\n",
    "#model.save( f'models/{VERSION}.checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plotter.losses(history)\n",
    "initial_epoch += 13\n",
    "model.save( f'models/{VERSION}.checkpoint.h5')\n",
    "\n",
    "#initial_epoch += EPOCHS\n",
    "#model.save( f'models/{VERSION}/{VERSION}.checkpoint.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "img_path = './images/BOLD5000_Stimuli/Scene_Stimuli/Presented_Stimuli/ImageNet/n01833805_1411.JPEG'\n",
    "my_image = imread(img_path)\n",
    "imshow(my_image)\n",
    "\n",
    "img = image.load_img(img_path, target_size=(32, 32))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)\n",
    "print(model.predict(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_sample = x_train[120]\n",
    "y_sample = y_train[120]\n",
    "print(x_sample.shape)\n",
    "imshow(x_sample)\n",
    "print(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
